{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RifatXia/Contest/blob/master/TestQuestion_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XseUgTiPUIOK",
        "outputId": "9f8ceb91-f97d-437d-cb68-d59966face40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "train images shape: (40000, 32, 32, 3)\n",
            "validation images shape: (10000, 32, 32, 3)\n",
            "test images shape: (10000, 32, 32, 3)\n"
          ]
        }
      ],
      "source": [
        "# loading CIFAR-10 dataset\n",
        "\n",
        "from google.colab import drive\n",
        "import pickle\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# mount google drive to access files\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# function to load a single batch of cifar-10 data\n",
        "def load_cifar10_batch(file):\n",
        "    with open(file, 'rb') as f:\n",
        "        batch = pickle.load(f, encoding='bytes')\n",
        "        images = batch[b'data']\n",
        "        labels = batch[b'labels']\n",
        "    images = images.reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)\n",
        "    return images, np.array(labels)\n",
        "\n",
        "# load all training batches\n",
        "data_dir = \"/content/drive/My Drive/dataset/cifar-10/cifar-10-batches-py/\"\n",
        "train_images, train_labels = [], []\n",
        "\n",
        "for i in range(1, 6):\n",
        "    file_path = os.path.join(data_dir, f\"data_batch_{i}\")\n",
        "    images, labels = load_cifar10_batch(file_path)\n",
        "    train_images.append(images)\n",
        "    train_labels.append(labels)\n",
        "\n",
        "train_images = np.concatenate(train_images)\n",
        "train_labels = np.concatenate(train_labels)\n",
        "\n",
        "# load the test batch\n",
        "test_images, test_labels = load_cifar10_batch(os.path.join(data_dir, \"test_batch\"))\n",
        "\n",
        "# split training data into training and validation sets\n",
        "val_split = 0.2  # 20% for validation\n",
        "num_val_samples = int(len(train_images) * val_split)\n",
        "val_images = train_images[:num_val_samples]\n",
        "val_labels = train_labels[:num_val_samples]\n",
        "train_images = train_images[num_val_samples:]\n",
        "train_labels = train_labels[num_val_samples:]\n",
        "\n",
        "print(f\"train images shape: {train_images.shape}\")\n",
        "print(f\"validation images shape: {val_images.shape}\")\n",
        "print(f\"test images shape: {test_images.shape}\")\n",
        "\n",
        "# normalize pixel values to range [0, 1]\n",
        "train_images = train_images.astype('float32') / 255.0\n",
        "val_images = val_images.astype('float32') / 255.0\n",
        "test_images = test_images.astype('float32') / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHQTe2caaC-Y",
        "outputId": "05554c13-e03b-49b8-a32a-13788a3f3acb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - accuracy: 0.4809 - loss: 1.4867 - val_accuracy: 0.5789 - val_loss: 1.2816\n",
            "Epoch 2/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6835 - loss: 0.8943 - val_accuracy: 0.6269 - val_loss: 1.0795\n",
            "Epoch 3/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7685 - loss: 0.6677 - val_accuracy: 0.6707 - val_loss: 0.9372\n",
            "Epoch 4/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8197 - loss: 0.5167 - val_accuracy: 0.6901 - val_loss: 0.9860\n",
            "Epoch 5/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8659 - loss: 0.3873 - val_accuracy: 0.7251 - val_loss: 0.9095\n",
            "Epoch 6/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9016 - loss: 0.2818 - val_accuracy: 0.7185 - val_loss: 0.9259\n",
            "Epoch 7/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9301 - loss: 0.2032 - val_accuracy: 0.7224 - val_loss: 1.0464\n",
            "Epoch 8/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9440 - loss: 0.1636 - val_accuracy: 0.7173 - val_loss: 1.0575\n",
            "Epoch 9/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9546 - loss: 0.1320 - val_accuracy: 0.7152 - val_loss: 1.2522\n",
            "Epoch 10/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9563 - loss: 0.1250 - val_accuracy: 0.7348 - val_loss: 1.2242\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7375 - loss: 1.2092\n",
            "validation accuracy: 0.7347999811172485\n"
          ]
        }
      ],
      "source": [
        "# basic cnn model for cifar-10\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# build the cnn model\n",
        "cnn_model_cifar10 = models.Sequential()\n",
        "\n",
        "# add an input layer to avoid warnings\n",
        "cnn_model_cifar10.add(layers.Input(shape=(32, 32, 3)))\n",
        "\n",
        "# first convolution block\n",
        "cnn_model_cifar10.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "cnn_model_cifar10.add(layers.MaxPooling2D((2, 2)))\n",
        "cnn_model_cifar10.add(layers.BatchNormalization())\n",
        "\n",
        "# second convolution block\n",
        "cnn_model_cifar10.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "cnn_model_cifar10.add(layers.MaxPooling2D((2, 2)))\n",
        "cnn_model_cifar10.add(layers.BatchNormalization())\n",
        "\n",
        "# third convolution block\n",
        "cnn_model_cifar10.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "cnn_model_cifar10.add(layers.MaxPooling2D((2, 2)))\n",
        "cnn_model_cifar10.add(layers.BatchNormalization())\n",
        "\n",
        "# flatten the output and pass through dense layers\n",
        "cnn_model_cifar10.add(layers.Flatten())\n",
        "cnn_model_cifar10.add(layers.Dense(128, activation='relu'))\n",
        "cnn_model_cifar10.add(layers.Dense(10, activation='softmax'))  # 10 classes in cifar-10\n",
        "\n",
        "# compile the model\n",
        "cnn_model_cifar10.compile(optimizer='adam',\n",
        "                           loss='sparse_categorical_crossentropy',\n",
        "                           metrics=['accuracy'])\n",
        "\n",
        "# train the model\n",
        "history_cifar10 = cnn_model_cifar10.fit(train_images, train_labels, epochs=10,\n",
        "                    validation_data=(val_images, val_labels))\n",
        "\n",
        "# evaluate the model on the validation set\n",
        "val_loss, val_acc = cnn_model_cifar10.evaluate(val_images, val_labels)\n",
        "print(f\"validation accuracy: {val_acc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "n1LqmDN4aeq8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b36395b-bc90-4422-f2b9-af7766d53337"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 16ms/step - accuracy: 0.4518 - loss: 1.6477 - val_accuracy: 0.5378 - val_loss: 1.3373\n",
            "Epoch 2/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 13ms/step - accuracy: 0.6894 - loss: 0.8844 - val_accuracy: 0.6644 - val_loss: 1.0225\n",
            "Epoch 3/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 14ms/step - accuracy: 0.7721 - loss: 0.6541 - val_accuracy: 0.7233 - val_loss: 0.8240\n",
            "Epoch 4/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 14ms/step - accuracy: 0.8287 - loss: 0.4934 - val_accuracy: 0.6827 - val_loss: 1.0117\n",
            "Epoch 5/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 14ms/step - accuracy: 0.8793 - loss: 0.3542 - val_accuracy: 0.7280 - val_loss: 0.8670\n",
            "Epoch 6/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - accuracy: 0.9155 - loss: 0.2434 - val_accuracy: 0.7479 - val_loss: 0.8947\n",
            "Epoch 7/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.9438 - loss: 0.1670 - val_accuracy: 0.7562 - val_loss: 0.9163\n",
            "Epoch 8/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.9567 - loss: 0.1309 - val_accuracy: 0.7665 - val_loss: 0.9383\n",
            "Epoch 9/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 13ms/step - accuracy: 0.9654 - loss: 0.1064 - val_accuracy: 0.7723 - val_loss: 0.9902\n",
            "Epoch 10/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.9668 - loss: 0.0954 - val_accuracy: 0.7278 - val_loss: 1.2821\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7234 - loss: 1.2762\n",
            "validation accuracy: 0.7278\n"
          ]
        }
      ],
      "source": [
        "# replacing the convolution block with inception block for cifar-10\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# define an inception block\n",
        "def inception_block(x, filters):\n",
        "    # 1x1 convolution\n",
        "    conv1x1 = layers.Conv2D(filters, (1, 1), padding='same', activation='relu')(x)\n",
        "\n",
        "    # 3x3 convolution\n",
        "    conv3x3 = layers.Conv2D(filters, (3, 3), padding='same', activation='relu')(x)\n",
        "\n",
        "    # 5x5 convolution\n",
        "    conv5x5 = layers.Conv2D(filters, (5, 5), padding='same', activation='relu')(x)\n",
        "\n",
        "    # max pooling followed by 1x1 convolution\n",
        "    max_pool = layers.MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "    max_pool_conv = layers.Conv2D(filters, (1, 1), padding='same', activation='relu')(max_pool)\n",
        "\n",
        "    # concatenate all the outputs\n",
        "    output = layers.Concatenate(axis=-1)([conv1x1, conv3x3, conv5x5, max_pool_conv])\n",
        "    return output\n",
        "\n",
        "# build the model using the functional api\n",
        "inputs = layers.Input(shape=(32, 32, 3))\n",
        "\n",
        "# first inception block\n",
        "x = inception_block(inputs, 32)\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "\n",
        "# second inception block\n",
        "x = inception_block(x, 64)\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "\n",
        "# third inception block\n",
        "x = inception_block(x, 128)\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "\n",
        "# flatten and pass through dense layers\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(128, activation='relu')(x)\n",
        "outputs = layers.Dense(10, activation='softmax')(x)  # 10 classes for cifar-10\n",
        "\n",
        "# create the model\n",
        "cnn_model_inception_cifar10 = models.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# compile the model\n",
        "cnn_model_inception_cifar10.compile(optimizer='adam',\n",
        "                                     loss='sparse_categorical_crossentropy',\n",
        "                                     metrics=['accuracy'])\n",
        "\n",
        "# train the model\n",
        "history_inception_cifar10 = cnn_model_inception_cifar10.fit(train_images, train_labels, epochs=10,\n",
        "                                                             validation_data=(val_images, val_labels))\n",
        "\n",
        "# evaluate the model on the validation set\n",
        "val_loss, val_acc = cnn_model_inception_cifar10.evaluate(val_images, val_labels)\n",
        "print(f\"validation accuracy: {val_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZWMC4swbmTy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1f47f56-4c66-41bd-80a0-7ca004808c2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 11ms/step - accuracy: 0.4469 - loss: 1.5713 - val_accuracy: 0.6413 - val_loss: 1.0502\n",
            "Epoch 2/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.7182 - loss: 0.7995 - val_accuracy: 0.7474 - val_loss: 0.7319\n",
            "Epoch 3/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.7842 - loss: 0.6102 - val_accuracy: 0.7546 - val_loss: 0.7173\n",
            "Epoch 4/10\n",
            "\u001b[1m 583/1250\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8327 - loss: 0.4791"
          ]
        }
      ],
      "source": [
        "# replacing the inception block using residual block for cifar-10\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# define a residual block\n",
        "def residual_block(x, filters):\n",
        "    shortcut = x  # save input for the skip connection\n",
        "\n",
        "    # first convolution layer\n",
        "    x = layers.Conv2D(filters, (3, 3), padding='same', activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    # second convolution layer\n",
        "    x = layers.Conv2D(filters, (3, 3), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    # if the number of channels of shortcut and x are different, apply a 1x1 convolution to shortcut\n",
        "    if shortcut.shape[-1] != x.shape[-1]:\n",
        "        shortcut = layers.Conv2D(filters, (1, 1), padding='same')(shortcut)\n",
        "\n",
        "    # skip connection: add input (shortcut) to output\n",
        "    x = layers.Add()([x, shortcut])\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "# build the model using the functional api\n",
        "inputs = layers.Input(shape=(32, 32, 3))\n",
        "\n",
        "# first residual block\n",
        "x = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(inputs)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = residual_block(x, 32)\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "# second residual block\n",
        "x = residual_block(x, 64)\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "# third residual block\n",
        "x = residual_block(x, 128)\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "# flatten and pass through dense layers\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(128, activation='relu')(x)\n",
        "outputs = layers.Dense(10, activation='softmax')(x)  # 10 classes for cifar-10\n",
        "\n",
        "# create the model\n",
        "cnn_model_residual_cifar10 = models.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# compile the model\n",
        "cnn_model_residual_cifar10.compile(optimizer='adam',\n",
        "                                    loss='sparse_categorical_crossentropy',\n",
        "                                    metrics=['accuracy'])\n",
        "\n",
        "# train the model\n",
        "history_residual_cifar10 = cnn_model_residual_cifar10.fit(train_images, train_labels, epochs=10,\n",
        "                                                          validation_data=(val_images, val_labels))\n",
        "\n",
        "# evaluate the model on the validation set\n",
        "val_loss, val_acc = cnn_model_residual_cifar10.evaluate(val_images, val_labels)\n",
        "print(f\"validation accuracy: {val_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33YkTu-nb6bk"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# evaluate all models on the test set\n",
        "test_loss_cnn, test_acc_cnn = cnn_model_cifar10.evaluate(test_images, test_labels)\n",
        "test_loss_inception, test_acc_inception = cnn_model_inception_cifar10.evaluate(test_images, test_labels)\n",
        "test_loss_residual, test_acc_residual = cnn_model_residual_cifar10.evaluate(test_images, test_labels)\n",
        "\n",
        "# print test accuracy for each model\n",
        "print(f\"Test Accuracy - CNN Model: {test_acc_cnn:.4f}\")\n",
        "print(f\"Test Accuracy - Inception Model: {test_acc_inception:.4f}\")\n",
        "print(f\"Test Accuracy - Residual Model: {test_acc_residual:.4f}\")\n",
        "\n",
        "# plot comparison graph\n",
        "models = [\"CNN\", \"Inception\", \"Residual\"]\n",
        "accuracy = [test_acc_cnn, test_acc_inception, test_acc_residual]\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(models, accuracy, color=['blue', 'green', 'red'])\n",
        "plt.ylim(0, 1)\n",
        "plt.xlabel(\"Model Type\")\n",
        "plt.ylabel(\"Test Accuracy\")\n",
        "plt.title(\"Comparison of Model Performance on Test Set\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNtCsgu7IAhrV6RC5a6WAV9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}